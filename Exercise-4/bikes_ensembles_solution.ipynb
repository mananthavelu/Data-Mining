{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To suppress Scikit-learn warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
       "0 2011-01-01 00:00:00       1        0           0        1  0.24  0.2879   \n",
       "1 2011-01-01 01:00:00       1        0           0        1  0.22  0.2727   \n",
       "2 2011-01-01 02:00:00       1        0           0        1  0.22  0.2727   \n",
       "3 2011-01-01 03:00:00       1        0           0        1  0.24  0.2879   \n",
       "4 2011-01-01 04:00:00       1        0           0        1  0.24  0.2879   \n",
       "\n",
       "   humidity  windspeed  casual  registered  count  \n",
       "0      0.81        0.0       3          13     16  \n",
       "1      0.80        0.0       8          32     40  \n",
       "2      0.80        0.0       5          27     32  \n",
       "3      0.75        0.0       3          10     13  \n",
       "4      0.75        0.0       0           1      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./train.csv', parse_dates=['datetime'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming raw features\n",
    "In one way or another, virtually any machine learning method is based on recognizing and leveraging similarities between instances in the training data. For this to be successful, features of the instances should describe these similarities in a meaningful fashion. This does not only concern individual instances, but also relationships between them.\n",
    "\n",
    "In this dataset, there are several examples of features that do not really satisfy this requirement, e.g., `weather`: is the distance between `weather=2` and `weather=4` really twice as big as between `weather=1` and `weather=2`? Similar reasoning applies to the raw `datetime` values.\n",
    "\n",
    "First, let's break down `datetime` into higher-level components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>2011-02-07 01:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>2011-11-01 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8429</th>\n",
       "      <td>2012-07-12 14:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>2012-02-08 05:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6192</th>\n",
       "      <td>2012-02-14 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                datetime  dow  year  month  hour\n",
       "573  2011-02-07 01:00:00    0  2011      2     1\n",
       "4519 2011-11-01 09:00:00    1  2011     11     9\n",
       "8429 2012-07-12 14:00:00    3  2012      7    14\n",
       "6047 2012-02-08 05:00:00    2  2012      2     5\n",
       "6192 2012-02-14 06:00:00    1  2012      2     6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['year']  = data['datetime'].dt.year\n",
    "data['month'] = data['datetime'].dt.month\n",
    "data['dow']   = data['datetime'].dt.dayofweek\n",
    "data['hour']  = data['datetime'].dt.hour\n",
    "\n",
    "data[['datetime', 'dow', 'year', 'month', 'hour']].sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding of categorical features\n",
    "Now, such attributes as `year`, `month`, or `hour`, are meaningful on their own. On the contrary, just like `weather`, `dow` (day of week) is not: is Saturday equal to two Thursdays? \n",
    "\n",
    "Such issues are solved by *one-hot encoding*, where a so-called *dummy* binary variable is introduced per value of a multi-valued categorical variable; for example, 7 dummy features for `dow`. Thus, a learning algorithm can identify whether the day of the week matters, but will not try to compare *between* days of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dow_0</th>\n",
       "      <th>dow_1</th>\n",
       "      <th>dow_2</th>\n",
       "      <th>dow_3</th>\n",
       "      <th>dow_4</th>\n",
       "      <th>dow_5</th>\n",
       "      <th>dow_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3963</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8976</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6983</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8536</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dow_0  dow_1  dow_2  dow_3  dow_4  dow_5  dow_6\n",
       "3963      0      0      0      0      1      0      0\n",
       "3490      1      0      0      0      0      0      0\n",
       "8976      0      0      0      1      0      0      0\n",
       "6983      1      0      0      0      0      0      0\n",
       "8536      0      1      0      0      0      0      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dow_df = pd.get_dummies(data['dow'], prefix='dow')\n",
    "dow_df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wthr_1</th>\n",
       "      <th>wthr_2</th>\n",
       "      <th>wthr_3</th>\n",
       "      <th>wthr_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10851</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6747</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10638</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5178</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10396</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wthr_1  wthr_2  wthr_3  wthr_4\n",
       "10851       1       0       0       0\n",
       "6747        0       1       0       0\n",
       "10638       0       0       1       0\n",
       "5178        1       0       0       0\n",
       "10396       1       0       0       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doing the same for `weather`\n",
    "wthr_df = pd.get_dummies(data['weather'], prefix='wthr')\n",
    "wthr_df.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `prepare_data` puts these transformations together, so that they can be conveniently applied to the *test* data as well as the training data: obviously, all features accessible at training time must also be accessible at prediction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(filename):\n",
    "    data = pd.read_csv(filename, parse_dates=['datetime'])\n",
    "    data['year']  = data['datetime'].dt.year\n",
    "    data['month'] = data['datetime'].dt.month\n",
    "    data['dow']   = data['datetime'].dt.dayofweek\n",
    "    data['hour']  = data['datetime'].dt.hour\n",
    "    \n",
    "    # `get_dummies` implements one-hot encoding\n",
    "    dow_df = pd.get_dummies(data['dow'], prefix='dow')\n",
    "    wthr_df = pd.get_dummies(data['weather'], prefix='wthr')\n",
    "    \n",
    "    # Attach generated features to the original data frame\n",
    "    data = pd.concat([data, dow_df, wthr_df], axis=1)\n",
    "\n",
    "    # Three lines below essentially\n",
    "    features = ['year', 'month', 'hour', 'holiday', 'workingday',\n",
    "                'temp', 'atemp', 'humidity', 'windspeed']\n",
    "    features += ['dow_%d'%i for i in range(7)]\n",
    "    features += ['wthr_%d'%i for i in range(1, 5)]\n",
    "    X = data[features].values\n",
    "\n",
    "    y = None\n",
    "    y_registered = None\n",
    "    y_casual = None\n",
    "    if 'count' in data.columns:\n",
    "        y = data['count'].values\n",
    "    if 'registered' in data.columns:\n",
    "        y_registered = data['registered'].values\n",
    "        y_casual = data['casual'].values\n",
    "    \n",
    "    return X, y, y_registered, y_casual\n",
    "\n",
    "X, y, y_registered, y_casual = prepare_data('./train.csv')\n",
    "X_test, _, _, _ = prepare_data('./test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection and evaluation\n",
    "Inevitably, coming up with a good prediction model requires several iterations of feature engineering, learner selection, parameter tuning, etc. The key challenge in this iterative process is to avoid overfitting, i.e. memorizing the training set as opposed to generalizing. To accomplish this, models must be tested on independent, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate validation set\n",
    "The easiest way to ensure this is to set a fixed part of the training set aside as an independent validation set, which models are never trained on. *Scikit-learn* provides a function for that, not so aptly called `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8164, 20) (8164,)\n",
      "(2722, 20) (2722,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cw/dtaijupiter/NoCsBack/dtai/evgeniya/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_validation.shape, y_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "Using a fixed validation has a number of downsides. Most importantly, only a part of the data is used for testing, which decreases reliability of score estimates and increases sensitivity to the split. *Cross-validation* improves on this by averaging the performance over a number of different splits, also known as *folds*, albeit at higher computational costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating a model\n",
    "We will evaluate the models using *Root Mean Squared Logarithmic Error*. This measure is not built in *Scikit-learn*. Nevertheless, it provides facilities to define and use new scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "import numpy as np\n",
    "\n",
    "def rmsle_func(y_actual, y_predicted):\n",
    "    sle = (np.log(y_predicted+1) - np.log(y_actual+1))**2\n",
    "    return np.sqrt(np.mean(sle))\n",
    "\n",
    "rmsle_loss = make_scorer(rmsle_func, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles\n",
    "The goal of ensemble methods is to combine the predictions of several base estimators built with a given learning algorithm in order to improve generalizability / robustness over a single estimator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "In boosting methods, several base estimators are built sequentially and then combined in order to produce a powerful ensemble.\n",
    "\n",
    "*AdaBoost* trains base models (e.g. `DecisionTreeRegressor` below) in sequence while simultaneously re-weighing instances based on how good their targets are to predict already, whereas *Random Forests* do so by sampling a subset of instances and attributes for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import  DecisionTreeRegressor\n",
    "\n",
    "tree_model = DecisionTreeRegressor(max_depth=5)\n",
    "adaboost_model = AdaBoostRegressor(DecisionTreeRegressor(max_depth=15), n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "params = {'n_estimators': 1000, 'max_depth': 15, 'random_state': 0, 'min_samples_split' : 5, 'n_jobs': -1}\n",
    "rf_model = RandomForestRegressor(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "Bootstrap aggregating, also called *bagging*, is a machine learning ensemble meta-algorithm that fits base models each on random subsets of the original dataset and then aggregates their individual predictions (either by voting or by averaging) to form a final prediction. \n",
    "\n",
    "Bagging reduces variance and helps to avoid overfitting. Although it is usually applied to decision tree methods, it can be used with any type of method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import  DecisionTreeRegressor\n",
    "\n",
    "bagging_model = BaggingRegressor(DecisionTreeRegressor(max_depth=15), n_estimators=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that to use cross-validation to compare performance of different models correctly, the folds must be identical for all of them. In *Scikit-learn*, this can be ensured by using the same *fold generator*, e.g. `KFold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DecisionTreeRegressor: RMSLE = 0.6101\n",
      "        AdaBoostRegressor: RMSLE = 0.4221\n",
      "    RandomForestRegressor: RMSLE = 0.3389\n",
      "         BaggingRegressor: RMSLE = 0.3373\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "cv_generator = KFold(len(X), n_folds=3, shuffle=True)\n",
    "\n",
    "def print_cv_score(model, name):\n",
    "    scores = cross_val_score(model, X, y, scoring=rmsle_loss, cv=cv_generator)\n",
    "    mean_score = -scores.mean()\n",
    "    print('%25s: RMSLE = %.4f'%(name, mean_score))\n",
    "\n",
    "# Compare performance of different models:   \n",
    "print_cv_score(tree_model,     'DecisionTreeRegressor')\n",
    "print_cv_score(adaboost_model, 'AdaBoostRegressor')\n",
    "print_cv_score(rf_model,       'RandomForestRegressor')\n",
    "print_cv_score(bagging_model,   'BaggingRegressor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using two models \n",
    "\n",
    "Sometimes the data is composed of subsets that are generated by widely different mechanisms. In such cases, one can break the prediction problem into multiple problems, treat them independently, and combine their results at the end.  \n",
    "\n",
    "In the previous sessions, we observed a difference in patterns of demands of *registered* and *casual* customers. We can build two models for predicting these two values independently, and combine the results to get the final prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32833365705\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for train_indices, validation_indices in cv_generator:\n",
    "    rf_model.fit(X[train_indices], y_casual[train_indices])\n",
    "    y_c_pred = rf_model.predict(X[validation_indices])\n",
    "    \n",
    "    rf_model.fit(X[train_indices], y_registered[train_indices])\n",
    "    y_r_pred = rf_model.predict(X[validation_indices])\n",
    "    \n",
    "    y_pred = y_c_pred + y_r_pred\n",
    "    y_pred[y_pred < 0] = 0\n",
    "    score = rmsle_func(y[validation_indices], y_pred)\n",
    "    \n",
    "    scores.append(score)\n",
    "print (np.mean(scores))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
